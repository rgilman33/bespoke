{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9778773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('1.13.1', 1, 'NVIDIA GeForce RTX 2070 with Max-Q Design')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(f'/home/beans/bespoke')\n",
    "\n",
    "from models import EffNet\n",
    "from constants import *\n",
    "from imports import *\n",
    "from train_utils import *\n",
    "\n",
    "torch.__version__, torch.cuda.device_count(), torch.cuda.get_device_name(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be31733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_tensorrt\n",
    "import timm\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "torch.hub._validate_not_a_forked_repo=lambda a,b,c: True\n",
    "\n",
    "#efficientnet_b0 = timm.create_model('efficientnet_b0',pretrained=True)\n",
    "#efficientnet = timm.create_model('efficientnet_b4',pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f13fb6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18297.787"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = EffNet().to(device) # 13M params, 11.6M without RNN, \n",
    "sum([torch.numel(p) for p in m.parameters()]) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66277ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = \"1.29_avg\"\n",
    "\n",
    "m.load_state_dict(torch.load(f\"{BESPOKE_ROOT}/models_deploy/m{stem}.torch\"), strict=False)\n",
    "backbone = m.backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bbdb109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://developer.nvidia.com/blog/accelerating-inference-up-to-6x-faster-in-pytorch-with-torch-tensorrt/\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "\n",
    "def benchmark(model, input_shape=(1024, 3, 512, 512), dtype='fp32', nwarmup=50, nruns=1000):\n",
    "    input_data = torch.randn(input_shape)\n",
    "    input_data = input_data.to(\"cuda\")\n",
    "    if dtype=='fp16':\n",
    "        input_data = input_data.half()\n",
    "        \n",
    "    print(\"Warm up ...\")\n",
    "    with torch.no_grad():\n",
    "        for _ in range(nwarmup):\n",
    "            features = model(input_data)\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"Start timing ...\")\n",
    "    timings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(1, nruns+1):\n",
    "            start_time = time.time()\n",
    "            pred_loc  = model(input_data)\n",
    "            torch.cuda.synchronize()\n",
    "            end_time = time.time()\n",
    "            timings.append(end_time - start_time)\n",
    "            if i%10==0:\n",
    "                print('Iteration %d/%d, avg batch time %.2f ms'%(i, nruns, np.mean(timings)*1000))\n",
    "\n",
    "    print(\"Input shape:\", input_data.size())\n",
    "    print('Average throughput: %.2f images/second'%(input_shape[0]/np.mean(timings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d760f236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_CHANNELS_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "634b2f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, N_CHANNELS_MODEL, IMG_HEIGHT, IMG_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d12aa8e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/10, avg batch time 30.71 ms\n",
      "Input shape: torch.Size([1, 4, 360, 1440])\n",
      "Average throughput: 32.57 images/second\n"
     ]
    }
   ],
   "source": [
    "model = backbone.eval().to(\"cuda\")\n",
    "benchmark(model, input_shape=input_shape, nruns=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9ead6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/10, avg batch time 25.33 ms\n",
      "Input shape: torch.Size([1, 4, 360, 1440])\n",
      "Average throughput: 39.48 images/second\n"
     ]
    }
   ],
   "source": [
    "traced_model = torch.jit.trace(model, torch.randn(input_shape).to(\"cuda\"))\n",
    "benchmark(traced_model, input_shape=input_shape, nruns=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40ed9918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42dc5fb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage. See `CUDA_MODULE_LOADING` in https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.6.0 but loaded cuDNN 8.5.0\n",
      "ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::145] Error Code 2: OutOfMemory (no further information)\n",
      "ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::145] Error Code 2: OutOfMemory (no further information)\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000004.\n",
      "Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().\n",
      "ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::145] Error Code 2: OutOfMemory (no further information)\n",
      "ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::145] Error Code 2: OutOfMemory (no further information)\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 8589934592 detected for tactic 0x000000000000003c.\n",
      "Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().\n",
      "ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::145] Error Code 2: OutOfMemory (no further information)\n",
      "ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::145] Error Code 2: OutOfMemory (no further information)\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000004.\n",
      "Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().\n",
      "ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::145] Error Code 2: OutOfMemory (no further information)\n",
      "ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::145] Error Code 2: OutOfMemory (no further information)\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 8589934592 detected for tactic 0x000000000000003c.\n",
      "Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().\n",
      "ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::145] Error Code 2: OutOfMemory (no further information)\n",
      "ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::145] Error Code 2: OutOfMemory (no further information)\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000004.\n",
      "Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().\n",
      "ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::145] Error Code 2: OutOfMemory (no further information)\n",
      "ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::145] Error Code 2: OutOfMemory (no further information)\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 8589934592 detected for tactic 0x000000000000003c.\n",
      "Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().\n",
      "ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::145] Error Code 2: OutOfMemory (no further information)\n",
      "ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::145] Error Code 2: OutOfMemory (no further information)\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000004.\n",
      "Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().\n",
      "ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::145] Error Code 2: OutOfMemory (no further information)\n",
      "ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::145] Error Code 2: OutOfMemory (no further information)\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 8589934592 detected for tactic 0x000000000000003c.\n",
      "Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.6.0 but loaded cuDNN 8.5.0\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT encountered issues when converting weights between types and that could affect accuracy.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Check verbose logs for the list of affected weights.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - - 150 weights are affected by this issue: Detected subnormal FP16 values.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - - 25 weights are affected by this issue: Detected values less "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trt_model = torch_tensorrt.compile(model, \n",
    "    inputs= [torch_tensorrt.Input(input_shape)],\n",
    "    enabled_precisions= { torch_tensorrt.dtype.half} # Run with FP16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9ae6ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(original_name=EfficientNet_trt)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d7c3d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.save(trt_model, f\"{BESPOKE_ROOT}/trt_models/backbone_trt.jit.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7aba703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/10, avg batch time 9.67 ms\n",
      "Input shape: torch.Size([1, 4, 360, 1440])\n",
      "Average throughput: 103.41 images/second\n"
     ]
    }
   ],
   "source": [
    "benchmark(trt_model, input_shape=input_shape, nruns=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98fa4cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e114044d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = nn.Linear(3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cb13146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.float32, torch.float32]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdef6da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
